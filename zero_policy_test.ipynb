{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMBivENg4ZHI89siZpq67w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lunathanael/chessnn/blob/main/zero_policy_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aEOVZHf_fRtr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "185b2e62-0b9d-4df5-e387-53ff705a1630"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chess\n",
            "  Downloading chess-1.10.0-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: chess\n",
            "Successfully installed chess-1.10.0\n"
          ]
        }
      ],
      "source": [
        "!pip install chess\n",
        "import chess\n",
        "import math\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from typing import List\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, ReLU, Add, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from threading import Thread, Event"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def residual_block(x, filters):\n",
        "    \"\"\"Create a residual block.\"\"\"\n",
        "    y = Conv2D(filters, kernel_size=3, padding='same')(x)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = ReLU()(y)\n",
        "    y = Conv2D(filters, kernel_size=3, padding='same')(y)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Add()([y, x])\n",
        "    y = ReLU()(y)\n",
        "    return y\n",
        "\n",
        "def make_network():\n",
        "    # Input layer\n",
        "    input_layer = Input(shape=(8, 8, 20))  # 8x8 grid with 20 features per cell\n",
        "\n",
        "    # Body\n",
        "    x = Conv2D(256, kernel_size=3, padding='same', activation='relu')(input_layer)\n",
        "    x = BatchNormalization()(x)\n",
        "    # 19 residual blocks\n",
        "    for _ in range(19):\n",
        "        x = residual_block(x, 256)  # Each block has two convolutional layers with 256 filters, kernel size 3x3\n",
        "\n",
        "    # Policy Head\n",
        "    policy_head = Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
        "    policy_head = BatchNormalization()(policy_head)\n",
        "    policy_head = Conv2D(73, kernel_size=1)(policy_head)  # Output 73 policies\n",
        "\n",
        "    # Value Head\n",
        "    value_head = Conv2D(1, kernel_size=1, activation='relu')(x)\n",
        "    value_head = BatchNormalization()(value_head)\n",
        "    value_head = Flatten()(value_head)\n",
        "    value_head = Dense(256, activation='relu')(value_head)\n",
        "    value_head = Dense(1, activation='tanh')(value_head)  # Output single value\n",
        "\n",
        "    # Create the model\n",
        "    model = tf.keras.Model(inputs=input_layer, outputs=[value_head, policy_head])\n",
        "    return model\n",
        "\n",
        "\n",
        "def ConstantPolicyHead(shape):\n",
        "    # Custom layer for policy head\n",
        "    class CPHead(tf.keras.layers.Layer):\n",
        "        def call(self, inputs):\n",
        "            return tf.constant(1/73, shape=shape)\n",
        "\n",
        "    return CPHead()\n",
        "\n",
        "def ConstantValueHead():\n",
        "    # Custom layer for value head\n",
        "    class CVHead(tf.keras.layers.Layer):\n",
        "        def call(self, inputs):\n",
        "            return tf.constant(0.5, shape=(1,))\n",
        "\n",
        "    return CVHead()\n",
        "\n",
        "class make_uniform_network():\n",
        "  def __init__(self):\n",
        "    self._val =  np.full((1,1,), 0.5)\n",
        "    self._policy = array2 = np.full((1, 8, 8, 73), 1/73)\n",
        "  def predict(self, input):\n",
        "    return self._val, self._policy\n"
      ],
      "metadata": {
        "id": "ABgGpmx0fWGi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helpers"
      ],
      "metadata": {
        "id": "P3mUyAMlzxsn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Config(object):\n",
        "\n",
        "  def __init__(self):\n",
        "    ### Self-Play\n",
        "    self.num_actors = 1 # not enough ram <- 5000\n",
        "\n",
        "    self.num_sampling_moves = 30\n",
        "    self.max_moves = 512  # for chess and shogi, 722 for Go.\n",
        "    self.num_simulations = 800\n",
        "\n",
        "    # Root prior exploration noise.\n",
        "    self.root_dirichlet_alpha = 0.3  # for chess, 0.03 for Go and 0.15 for shogi.\n",
        "    self.root_exploration_fraction = 0.25\n",
        "\n",
        "    # UCB formula\n",
        "    self.pb_c_base = 19652\n",
        "    self.pb_c_init = 1.25\n",
        "\n",
        "    ### Training\n",
        "    self.training_steps = int(100e3) # 700,000 take too long, temp\n",
        "    self.checkpoint_interval = int(1e3)\n",
        "    self.window_size = int(1e6)\n",
        "    self.batch_size = 4096\n",
        "\n",
        "    self.weight_decay = 1e-4\n",
        "    self.momentum = 0.9\n",
        "    # Schedule for chess and shogi, Go starts at 2e-2 immediately.\n",
        "    self.learning_rate_schedule = {\n",
        "        0: 2e-1,\n",
        "        100e3: 2e-2,\n",
        "        300e3: 2e-3,\n",
        "        500e3: 2e-4\n",
        "    }"
      ],
      "metadata": {
        "id": "t32QDQxky6Yn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Node(object):\n",
        "\n",
        "  def __init__(self, prior: float):\n",
        "    self.visit_count = 0\n",
        "    self.to_play = -1\n",
        "    self.prior = prior\n",
        "    self.value_sum = 0\n",
        "    self.children = {}\n",
        "\n",
        "  def expanded(self):\n",
        "    return len(self.children) > 0\n",
        "\n",
        "  def value(self):\n",
        "    if self.visit_count == 0:\n",
        "      return 0\n",
        "    return self.value_sum / self.visit_count\n"
      ],
      "metadata": {
        "id": "Lvmt70d1y8HR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fen_to_repr(fen, repeats):\n",
        "    # Split the FEN string to get the relevant parts\n",
        "    parts = fen.split(' ')\n",
        "    board_fen, player, castling, _, halfmove, fullmove = parts[:6]\n",
        "\n",
        "    # 12 pieces, 4 cf, col, rep, half, total\n",
        "    board = np.zeros((8, 8, 12 + 4 + 1 + 1 + 1 + 1), dtype=float)\n",
        "\n",
        "    # Define piece order and mapping to layers\n",
        "    piece_map = {'p': 0, 'n': 1, 'b': 2, 'r': 3, 'q': 4, 'k': 5,\n",
        "                 'P': 6, 'N': 7, 'B': 8, 'R': 9, 'Q': 10, 'K': 11}\n",
        "\n",
        "    # Fill the board with pieces\n",
        "    row = 0\n",
        "    col = 0\n",
        "    for char in board_fen:\n",
        "        if char.isdigit():\n",
        "            col += int(char)\n",
        "        elif char == '/':\n",
        "            row += 1\n",
        "            col = 0\n",
        "        else:\n",
        "            board[row, col, piece_map[char]] = 1\n",
        "            col += 1\n",
        "\n",
        "    # Castling rights encoded in four binary planes\n",
        "    board[:, :, 12] = 1 if 'K' in castling else 0  # White kingside\n",
        "    board[:, :, 13] = 1 if 'Q' in castling else 0  # White queenside\n",
        "    board[:, :, 14] = 1 if 'k' in castling else 0  # Black kingside\n",
        "    board[:, :, 15] = 1 if 'q' in castling else 0  # Black queenside\n",
        "\n",
        "    # Player color (1 for black, 0 for white)\n",
        "    board[:, :, 16] = 1 if player == 'b' else 0\n",
        "\n",
        "    # Position repetitions\n",
        "    board[:, :, 17] = repeats\n",
        "\n",
        "    board[:, :, 18] = float(halfmove)\n",
        "\n",
        "    # Move number (as a real value)\n",
        "    board[:, :, 19] = float(fullmove)\n",
        "\n",
        "    return board"
      ],
      "metadata": {
        "id": "1LZ0finYdR6k"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def square_to_coord(square):\n",
        "  #       r           c\n",
        "  return (square // 8, square % 8)\n",
        "\n",
        "knight_moves = [\n",
        "    (1, 2), (1, -2),\n",
        "    (2, 1), (2, -1),\n",
        "    (-1, 2), (-1, -2),\n",
        "    (-2, 1), (-2, -1)\n",
        "]\n",
        "\n",
        "promotion_pieces = \"nbr\"\n",
        "rows = \"abcdefgh\"\n",
        "\n",
        "queen_moves = [\n",
        "    (1, 1), (1, -1), (1, 0),\n",
        "    (-1, 1), (-1, -1), (-1, 0),\n",
        "    (0, 1), (0, -1)\n",
        "]\n",
        "\n",
        "def coord_to_uci(fr, fc, tr, tc):\n",
        "  return rows[fc] + str(fr + 1) + rows[tc] + str(tr + 1)\n",
        "\n",
        "def decode_action(action):\n",
        "\n",
        "  #piece = self.board.piece_at(move.from_square)\n",
        "  #fr, fc = square_to_coord(move.from_square)\n",
        "  #tr, tc = square_to_coord(move.to_square)\n",
        "  fr = action[0]\n",
        "  fc = action[1]\n",
        "\n",
        "  if action[2] < 9:\n",
        "    piece_idx = action[2] // 3\n",
        "    move_idx = action[2] % 3\n",
        "    if fr == 1: # black promo\n",
        "      tr = 0\n",
        "    else:\n",
        "      tr = 7\n",
        "    if move_idx == 0:\n",
        "      tc = fc\n",
        "    elif move_idx == 1:\n",
        "      tc = fc - 1\n",
        "    else:\n",
        "      tc = fc + 1\n",
        "    return coord_to_uci(fr, fc, tr, tc) + promotion_pieces[piece_idx]\n",
        "\n",
        "  if action[2] < 17:\n",
        "    tr = fr + knight_moves[action[2] - 9][0]\n",
        "    tc = fc + knight_moves[action[2] - 9][1]\n",
        "  else:\n",
        "    dist = (action[2] - 17) // 8 + 1\n",
        "    status = (action[2] - 17) % 8\n",
        "    tr = fr + (queen_moves[status][0] * dist)\n",
        "    tc = fc + (queen_moves[status][1] * dist)\n",
        "\n",
        "  return coord_to_uci(fr, fc, tr, tc)\n",
        "\n",
        "\n",
        "class Environment(object):\n",
        "\n",
        "  def __init__(self, env=None):\n",
        "    if env == None:\n",
        "      self.board = chess.Board(chess.STARTING_FEN)\n",
        "      self.board_history = []\n",
        "      self.repetitions = {}\n",
        "\n",
        "      self.update_history()\n",
        "    else:\n",
        "      self.board = chess.Board.copy(env.board)\n",
        "      self.board_history = env.board_history.copy()\n",
        "      self.repetitions = env.repetitions.copy()\n",
        "\n",
        "  def is_terminal(self):\n",
        "    return self.board.is_game_over()\n",
        "\n",
        "  def terminal_value(self, to_play):\n",
        "    if self.board.is_checkmate():\n",
        "      color = self.board.outcome.winner\n",
        "      color = (color == chess.BLACK)\n",
        "      return color == to_play\n",
        "    else:\n",
        "      return 0.5\n",
        "\n",
        "  def generate_legal_moves(self):\n",
        "    return self.board.generate_legal_moves()\n",
        "\n",
        "  def encode_action(self, move): #12 piece types, 4 flags, 2 coords\n",
        "\n",
        "    piece = self.board.piece_at(move.from_square)\n",
        "    fr, fc = square_to_coord(move.from_square)\n",
        "    tr, tc = square_to_coord(move.to_square)\n",
        "\n",
        "    if move.promotion and move.promotion != 5: # 9 planes\n",
        "      # move.promotion -> 2 : N, 3 : B, 4 : R, 5 : Q\n",
        "      piece_idx = move.promotion - 2\n",
        "      if fc == tc:\n",
        "        move_idx = 0\n",
        "      elif tc < fc: # left from white perspective\n",
        "        move_idx = 1\n",
        "      else:\n",
        "        move_idx = 2\n",
        "      plane = piece_idx * 3 + move_idx\n",
        "\n",
        "    elif str(piece).lower() == 'n': # 8 planes\n",
        "      for idx in range(len(knight_moves)):\n",
        "        if fr + knight_moves[idx][0] == tr and fc + knight_moves[idx][1] == tc:\n",
        "          plane = idx + 9\n",
        "          break\n",
        "\n",
        "    else: # 7 * 8 planes\n",
        "      if fr < tr: # moving forward\n",
        "        row_status = 0\n",
        "      elif fr > tr: # back\n",
        "        row_status = 1\n",
        "      else: # horizontal movement\n",
        "        row_status = 2\n",
        "\n",
        "      if fc < tc: # moving right\n",
        "        col_status = 0\n",
        "      elif fc > tc: # left\n",
        "        col_status = 1\n",
        "      else: # vertical movement\n",
        "        col_status = 2\n",
        "\n",
        "      # row status and col status should never both be 2, means something stinky\n",
        "\n",
        "      dist = max(abs(fr - tr), abs(fc - tc)) - 1\n",
        "      plane = dist * 8 + (row_status * 3 + col_status) + 17\n",
        "\n",
        "    # if decode_action((fr, fc, plane)) != str(move):\n",
        "    #   print(\"found diff\")\n",
        "    #   print(\"action: \", fr, fc, plane)\n",
        "    #   print(\"decoded: \", decode_action((fr, fc, plane)))\n",
        "    #   print(\"Coords: \", fr, fc, tr, tc)\n",
        "    #   print(move)\n",
        "    #   print(str(move) == coord_to_uci(fr, fc, tr, tc))\n",
        "    #   raise Exception(\"found differing in uci\")\n",
        "\n",
        "    return (fr, fc, plane)\n",
        "\n",
        "  def apply(self, action):\n",
        "    uci = decode_action(action)\n",
        "    if action[0] == 1 and len(uci) == 4 and str(self.board.piece_at(action[0]*8+action[1])) == 'p':\n",
        "      uci += 'q'\n",
        "    if action[0] == 6 and len(uci) == 4 and str(self.board.piece_at(action[0]*8+action[1])) == 'P':\n",
        "      uci += 'q'\n",
        "    self.board.push_uci(uci)\n",
        "    self.update_history()\n",
        "    #print(self.board)\n",
        "\n",
        "  def generate_legal_actions(self):\n",
        "    moves = self.generate_legal_moves()\n",
        "    actions = [self.encode_action(move) for move in moves]\n",
        "    return actions\n",
        "\n",
        "  def update_history(self):\n",
        "    fen = self.board.fen()\n",
        "    s_fen = fen.split(' ')\n",
        "    cs_fen = ' '.join(s_fen[:-2])\n",
        "\n",
        "    if cs_fen in self.repetitions:\n",
        "      self.repetitions[cs_fen] += 1\n",
        "      repeats = self.repetitions[cs_fen]\n",
        "    else:\n",
        "      self.repetitions[cs_fen] = 1\n",
        "      repeats = 1\n",
        "\n",
        "    halfmove_clock = self.board.halfmove_clock\n",
        "    self.board_history.append((fen, repeats))\n",
        "\n",
        "  def make_image(self, state_index=-1):\n",
        "    fen, repeats= self.board_history[state_index]\n",
        "\n",
        "    repr = fen_to_repr(fen, repeats)\n",
        "    return repr"
      ],
      "metadata": {
        "id": "3FE-c9peKBP2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Game(object):\n",
        "\n",
        "  def __init__(self, history=None, environment=None):\n",
        "    self.history = history or []\n",
        "    self.child_visits = []\n",
        "    self.num_actions = 4672  # action space size for chess\n",
        "    self.environment = Environment(environment)\n",
        "\n",
        "  def terminal(self):\n",
        "    # Game specific termination rules.\n",
        "    return self.environment.is_terminal()\n",
        "\n",
        "  def terminal_value(self, to_play):\n",
        "    # Game specific value.\n",
        "    return self.environment.terminal_value()\n",
        "\n",
        "  def legal_actions(self):\n",
        "    # Game specific calculation of legal actions.\n",
        "    return self.environment.generate_legal_actions()\n",
        "\n",
        "  def clone(self):\n",
        "    return Game(list(self.history), self.environment)\n",
        "\n",
        "  def apply(self, action):\n",
        "    self.history.append(action)\n",
        "    self.environment.apply(action)\n",
        "\n",
        "  def store_search_statistics(self, root):\n",
        "    sum_visits = sum(child.visit_count for child in root.children.values())\n",
        "    self.child_visits.append([\n",
        "        root.children[a].visit_count / sum_visits if a in root.children else 0\n",
        "        for a in range(self.num_actions)\n",
        "    ])\n",
        "\n",
        "  def make_image(self, state_index: int):\n",
        "    # Game specific feature planes.\n",
        "    return self.environment.make_image(state_index)\n",
        "\n",
        "  def make_target(self, state_index: int):\n",
        "    return (self.terminal_value(state_index % 2),\n",
        "            self.child_visits[state_index])\n",
        "\n",
        "  def to_play(self):\n",
        "    return len(self.history) % 2\n"
      ],
      "metadata": {
        "id": "rSCKGOM9zjwa"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "buffer_full_event = Event()"
      ],
      "metadata": {
        "id": "LC00N5YRH6dk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReplayBuffer(object):\n",
        "\n",
        "  def __init__(self, config: Config):\n",
        "    self.window_size = config.window_size\n",
        "    self.batch_size = config.batch_size\n",
        "    self.buffer = []\n",
        "\n",
        "  def save_game(self, game):\n",
        "    if len(self.buffer) > self.window_size:\n",
        "      buffer_full_event.set()\n",
        "      self.buffer.pop(0)\n",
        "    self.buffer.append(game)\n",
        "    print(\"Game saved\")\n",
        "\n",
        "  def sample_batch(self):\n",
        "    # Sample uniformly across positions.\n",
        "    print(\"Sample from: \", len(self.buffer))\n",
        "    move_sum = float(sum(len(g.history) for g in self.buffer))\n",
        "    games = np.random.choice(\n",
        "        self.buffer,\n",
        "        size=self.batch_size,\n",
        "        p=[len(g.history) / move_sum for g in self.buffer])\n",
        "    game_pos = [(g, np.random.randint(len(g.history))) for g in games]\n",
        "    return [(g.make_image(i), g.make_target(i)) for (g, i) in game_pos]"
      ],
      "metadata": {
        "id": "En06LbK6zoRk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Network(object):\n",
        "\n",
        "  def __init__(self, uniform_model: bool=False):\n",
        "    if uniform_model:\n",
        "      self.model = make_uniform_network()\n",
        "    else:\n",
        "      print(\"New network created.\")\n",
        "      self.model = make_network()\n",
        "\n",
        "  def inference(self, image): # inference for SINGLE IMAGE\n",
        "      # Run the neural network model to get predictions\n",
        "      image = np.expand_dims(image, axis=0)\n",
        "      value, policy_logits = self.model.predict(image, verbose=0)\n",
        "\n",
        "      value = value[0] # The value output is a scalar representing the predicted game outcome\n",
        "      policy_logits = policy_logits[0]\n",
        "\n",
        "      return value, np.array(policy_logits)\n",
        "\n",
        "  def batch_inference(self, images):\n",
        "    # Run the neural network model to get predictions\n",
        "    values, policy_logits = self.model.predict(images, verbose=0)\n",
        "\n",
        "    return values, np.array(policy_logits)\n",
        "\n",
        "\n",
        "  def get_weights(self):\n",
        "    # Returns the weights of this network.\n",
        "    return self.model.get_weights()"
      ],
      "metadata": {
        "id": "HPr_d9UOzqBG"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SharedStorage(object):\n",
        "\n",
        "  def __init__(self):\n",
        "    self._networks = {}\n",
        "\n",
        "  def latest_network(self) -> Network:\n",
        "    if self._networks:\n",
        "      return self._networks[max(self._networks.keys())]\n",
        "    else:\n",
        "      return Network(True)  # policy -> uniform, value -> 0.5\n",
        "\n",
        "  def save_network(self, step: int, network: Network):\n",
        "    self._networks[step] = network\n"
      ],
      "metadata": {
        "id": "6UsTnTQKzreQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training is split into two independent parts: Network training and\n",
        "# self-play data generation.\n",
        "# These two parts only communicate by transferring the latest network checkpoint\n",
        "# from the training to the self-play, and the finished games from the self-play\n",
        "# to the training.\n",
        "def zero(config: Config):\n",
        "  storage = SharedStorage()\n",
        "  replay_buffer = ReplayBuffer(config)\n",
        "  run_selfplay(config, storage, replay_buffer)\n",
        "  threads = [Thread(target=run_selfplay, args=(config, storage, replay_buffer))\n",
        "            for _ in range(config.num_actors)]\n",
        "\n",
        "  for t in threads:\n",
        "    t.start()\n",
        "\n",
        "  print(\"Self-play data generation launched.\")\n",
        "\n",
        "  train_network(config, storage, replay_buffer)\n",
        "\n",
        "  return storage.latest_network()\n",
        "\n"
      ],
      "metadata": {
        "id": "tV9QkBmLBKT9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##################################\n",
        "####### Part 1: Self-Play ########\n",
        "\n",
        "\n",
        "# Each self-play job is independent of all others; it takes the latest network\n",
        "# snapshot, produces a game and makes it available to the training job by\n",
        "# writing it to a shared replay buffer.\n",
        "def run_selfplay(config: Config, storage: SharedStorage,\n",
        "                 replay_buffer: ReplayBuffer):\n",
        "  while True:\n",
        "    network = storage.latest_network()\n",
        "    game = play_game(config, network)\n",
        "    replay_buffer.save_game(game)\n",
        "\n",
        "\n",
        "# Each game is produced by starting at the initial board position, then\n",
        "# repeatedly executing a Monte Carlo Tree Search to generate moves until the end\n",
        "# of the game is reached.\n",
        "def play_game(config: Config, network: Network):\n",
        "  game = Game()\n",
        "  while not game.terminal() and len(game.history) < config.max_moves:\n",
        "    action, root = run_mcts(config, game, network)\n",
        "    game.apply(action)\n",
        "    game.store_search_statistics(root)\n",
        "  return game\n",
        "\n",
        "\n",
        "# Core Monte Carlo Tree Search algorithm.\n",
        "# To decide on an action, we run N simulations, always starting at the root of\n",
        "# the search tree and traversing the tree according to the UCB formula until we\n",
        "# reach a leaf node.\n",
        "def run_mcts(config: Config, game: Game, network: Network):\n",
        "  root = Node(0)\n",
        "  evaluate(root, game, network)\n",
        "  add_exploration_noise(config, root)\n",
        "\n",
        "  for _ in range(config.num_simulations):\n",
        "    node = root\n",
        "    scratch_game = game.clone()\n",
        "    search_path = [node]\n",
        "\n",
        "    while node.expanded():\n",
        "      action, node = select_child(config, node)\n",
        "      scratch_game.apply(action)\n",
        "      search_path.append(node)\n",
        "\n",
        "    value = evaluate(node, scratch_game, network)\n",
        "    backpropagate(search_path, value, scratch_game.to_play())\n",
        "  return select_action(config, game, root), root\n",
        "\n",
        "\n",
        "\n",
        "def softmax_sample(visit_counts, temperature=10.0):\n",
        "    counts, actions = zip(*visit_counts)\n",
        "    # Apply softmax with temperature\n",
        "    counts = np.array(counts)\n",
        "    counts = counts / temperature  # Apply temperature scaling\n",
        "    softmax_probs = np.exp(counts) / sum(np.exp(counts))\n",
        "    # Sample an action based on the softmax probabilities\n",
        "    rnd_idx = np.random.choice(len(actions), p=softmax_probs)\n",
        "    action = actions[rnd_idx]\n",
        "    return softmax_probs, action\n",
        "\n",
        "\n",
        "def select_action(config: Config, game: Game, root: Node):\n",
        "  visit_counts = [(child.visit_count, action)\n",
        "                  for action, child in root.children.items()]\n",
        "  if len(game.history) < config.num_sampling_moves:\n",
        "    _, action = softmax_sample(visit_counts)\n",
        "  else:\n",
        "    _, action = max(visit_counts)\n",
        "  return action\n",
        "\n",
        "\n",
        "# Select the child with the highest UCB score.\n",
        "def select_child(config: Config, node: Node):\n",
        "  _, action, child = max((ucb_score(config, node, child), action, child)\n",
        "                         for action, child in node.children.items())\n",
        "  return action, child\n",
        "\n",
        "\n",
        "# The score for a node is based on its value, plus an exploration bonus based on\n",
        "# the prior.\n",
        "def ucb_score(config: Config, parent: Node, child: Node):\n",
        "  pb_c = math.log((parent.visit_count + config.pb_c_base + 1) /\n",
        "                  config.pb_c_base) + config.pb_c_init\n",
        "  pb_c *= math.sqrt(parent.visit_count) / (child.visit_count + 1)\n",
        "\n",
        "  prior_score = pb_c * child.prior\n",
        "  value_score = child.value()\n",
        "  return prior_score + value_score\n",
        "\n",
        "\n",
        "# We use the neural network to obtain a value and policy prediction.\n",
        "def evaluate(node: Node, game: Game, network: Network):\n",
        "  value, policy_logits = network.inference(game.make_image(-1))\n",
        "\n",
        "  # Expand the node.\n",
        "  node.to_play = game.to_play()\n",
        "\n",
        "  policy = {a: math.exp(policy_logits[a]) for a in game.legal_actions()}\n",
        "  policy_sum = sum(policy.values())\n",
        "  for action, p in policy.items():\n",
        "    node.children[action] = Node(p / policy_sum)\n",
        "  return value\n",
        "\n",
        "\n",
        "# At the end of a simulation, we propagate the evaluation all the way up the\n",
        "# tree to the root.\n",
        "def backpropagate(search_path: List[Node], value: float, to_play):\n",
        "  for node in search_path:\n",
        "    node.value_sum += value if node.to_play == to_play else (1 - value)\n",
        "    node.visit_count += 1\n",
        "\n",
        "\n",
        "# At the start of each search, we add dirichlet noise to the prior of the root\n",
        "# to encourage the search to explore new actions.\n",
        "def add_exploration_noise(config: Config, node: Node):\n",
        "  actions = node.children.keys()\n",
        "  noise = np.random.gamma(config.root_dirichlet_alpha, 1, len(actions))\n",
        "  frac = config.root_exploration_fraction\n",
        "  for a, n in zip(actions, noise):\n",
        "    node.children[a].prior = node.children[a].prior * (1 - frac) + n * frac\n",
        "\n",
        "\n",
        "######### End Self-Play ##########\n",
        "##################################\n",
        "\n",
        "##################################\n",
        "####### Part 2: Training #########\n",
        "\n",
        "class ZeroLearningRateSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, lr_schedule):\n",
        "        super(ZeroLearningRateSchedule, self).__init__()\n",
        "        # Convert keys to integers\n",
        "        self.lr_schedule = {int(k): v for k, v in lr_schedule.items()}\n",
        "        self.lr_schedule_keys = sorted(self.lr_schedule)\n",
        "\n",
        "    def __call__(self, step):\n",
        "        learning_rate = self.lr_schedule[self.lr_schedule_keys[0]]\n",
        "        for i in range(1, len(self.lr_schedule_keys)):\n",
        "            if step < self.lr_schedule_keys[i]:\n",
        "                break\n",
        "            learning_rate = self.lr_schedule[self.lr_schedule_keys[i]]\n",
        "        return learning_rate\n",
        "\n",
        "    def get_config(self):\n",
        "        return {'lr_schedule': self.lr_schedule}\n",
        "\n",
        "\n",
        "def train_network(config: Config, storage: SharedStorage,\n",
        "                  replay_buffer: ReplayBuffer):\n",
        "  print(\"Waiting...\")\n",
        "  buffer_full_event.wait() # wait for full buffer\n",
        "\n",
        "  network = Network()\n",
        "  learning_rate_schedule = ZeroLearningRateSchedule(config.learning_rate_schedule)\n",
        "  optimizer = tf.keras.optimizers.SGD(learning_rate_schedule, config.momentum)\n",
        "  for i in range(config.training_steps):\n",
        "    if i and i % config.checkpoint_interval == 0: # skip first checkpoint\n",
        "      print(\"Checkpoint: \", i // config.checkpoint_interval)\n",
        "      storage.save_network(i, network)\n",
        "    batch = replay_buffer.sample_batch()\n",
        "    update_weights(optimizer, network, batch, config.weight_decay)\n",
        "  storage.save_network(config.training_steps, network)\n",
        "\n",
        "def update_weights(optimizer: tf.keras.optimizers, network: Network, batch,\n",
        "                   weight_decay: float):\n",
        "  loss = 0\n",
        "  for image, (target_value, target_policy) in batch:\n",
        "    value, policy_logits = network.inference(image)\n",
        "    loss += (\n",
        "        tf.losses.mean_squared_error(value, target_value) +\n",
        "        tf.nn.softmax_cross_entropy_with_logits(\n",
        "            logits=policy_logits, labels=target_policy))\n",
        "\n",
        "  for weights in network.get_weights():\n",
        "    loss += weight_decay * tf.nn.l2_loss(weights)\n",
        "\n",
        "  optimizer.minimize(loss)\n",
        "\n",
        "\n",
        "######### End Training ###########\n",
        "##################################\n",
        "\n",
        "\n",
        "def launch_job(f, *args):\n",
        "  f(*args)"
      ],
      "metadata": {
        "id": "Ou5wkaIzpvvk"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cProfile\n",
        "config = Config()\n",
        "game = Game()\n",
        "nn = Network()\n",
        "\n",
        "with cProfile.Profile() as pr:\n",
        "  pass\n",
        "  #run_mcts(config, game, nn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fu2dOcAslSq",
        "outputId": "c332bd00-1dfd-4bde-9705-b77acd6ce841"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New network created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = Game().make_image(-1)\n",
        "images = np.repeat([image], 4, axis = 0)"
      ],
      "metadata": {
        "id": "m1IFfdqE76Qb"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "batch_size = 1\n",
        "for _ in range(10):\n",
        "  images = np.repeat([image], batch_size, axis=0)\n",
        "  start = time.time()\n",
        "  for _ in range(5):\n",
        "    nn.batch_inference(images)\n",
        "  end = time.time()\n",
        "  tot = end - start\n",
        "  print(\"Batch size: \", batch_size, \", total time: \", tot, \"per image: \", tot / (5*batch_size))\n",
        "  batch_size *= 2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbo2fbFv9SMA",
        "outputId": "21ed68fa-f15d-45aa-e034-2984453c4f30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size:  1 , total time:  0.8363618850708008 per image:  0.16727237701416015\n",
            "Batch size:  2 , total time:  0.9925093650817871 per image:  0.0992509365081787\n",
            "Batch size:  4 , total time:  1.5382449626922607 per image:  0.07691224813461303\n",
            "Batch size:  8 , total time:  2.502981662750244 per image:  0.06257454156875611\n",
            "Batch size:  16 , total time:  5.374805450439453 per image:  0.06718506813049316\n",
            "Batch size:  32 , total time:  8.913215160369873 per image:  0.055707594752311705\n",
            "Batch size:  64 , total time:  23.94163727760315 per image:  0.07481761649250984\n",
            "Batch size:  128 , total time:  41.41246843338013 per image:  0.06470698192715645\n",
            "Batch size:  256 , total time:  86.44875288009644 per image:  0.06753808818757534\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)\n",
        "nn.inference(image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obZcww0s7-Jn",
        "outputId": "b2d12ba7-f614-42c5-9b30-75122d84b813"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 105ms/step\n",
            "1/1 [==============================] - 0s 244ms/step\n",
            "1/1 [==============================] - 0s 105ms/step\n",
            "1/1 [==============================] - 0s 105ms/step\n",
            "1/1 [==============================] - 0s 193ms/step\n",
            "1/1 [==============================] - 0s 215ms/step\n",
            "1/1 [==============================] - 0s 157ms/step\n",
            "1/1 [==============================] - 0s 145ms/step\n",
            "1/1 [==============================] - 0s 151ms/step\n",
            "1/1 [==============================] - 0s 153ms/step\n",
            "1/1 [==============================] - 0s 147ms/step\n",
            "1/1 [==============================] - 0s 196ms/step\n",
            "1/1 [==============================] - 0s 228ms/step\n",
            "1/1 [==============================] - 0s 170ms/step\n",
            "1/1 [==============================] - 0s 165ms/step\n",
            "1/1 [==============================] - 0s 151ms/step\n",
            "1/1 [==============================] - 0s 149ms/step\n",
            "1/1 [==============================] - 0s 154ms/step\n",
            "1/1 [==============================] - 0s 92ms/step\n",
            "1/1 [==============================] - 0s 97ms/step\n",
            "1/1 [==============================] - 0s 85ms/step\n",
            "1/1 [==============================] - 0s 88ms/step\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "1/1 [==============================] - 0s 86ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 99ms/step\n",
            "1/1 [==============================] - 0s 103ms/step\n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "1/1 [==============================] - 0s 94ms/step\n",
            "1/1 [==============================] - 0s 91ms/step\n",
            "1/1 [==============================] - 0s 91ms/step\n",
            "1/1 [==============================] - 0s 107ms/step\n",
            "1/1 [==============================] - 0s 101ms/step\n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "1/1 [==============================] - 0s 96ms/step\n",
            "1/1 [==============================] - 0s 118ms/step\n",
            "1/1 [==============================] - 0s 102ms/step\n",
            "1/1 [==============================] - 0s 107ms/step\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "1/1 [==============================] - 0s 94ms/step\n",
            "1/1 [==============================] - 0s 92ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 89ms/step\n",
            "1/1 [==============================] - 0s 109ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.73793906], dtype=float32),\n",
              " array([[[-1.58127356e+00,  4.11895573e-01, -4.11278784e-01, ...,\n",
              "          -3.56388897e-01,  6.53102756e-01,  9.71852422e-01],\n",
              "         [-1.65438128e+00,  3.92223477e-01, -8.23434949e-01, ...,\n",
              "          -6.47575259e-01,  3.86123240e-01,  6.37032866e-01],\n",
              "         [-2.03502178e+00,  1.17488456e+00, -9.11915064e-01, ...,\n",
              "          -3.86198848e-01,  6.65799141e-01,  3.04536015e-01],\n",
              "         ...,\n",
              "         [-9.01853561e-01,  9.52573299e-01, -1.90259010e-01, ...,\n",
              "          -6.36822104e-01,  1.17242253e+00,  1.23982236e-01],\n",
              "         [-1.30446613e+00,  1.08352983e+00, -5.80132231e-02, ...,\n",
              "          -2.71797180e-01,  1.04940069e+00,  9.14379179e-01],\n",
              "         [-6.66254580e-01,  9.44324851e-01,  3.25394988e-01, ...,\n",
              "          -6.79210052e-02,  5.79576135e-01,  4.42014426e-01]],\n",
              " \n",
              "        [[-1.35103846e+00,  3.65273297e-01, -3.22516650e-01, ...,\n",
              "          -3.88961285e-01,  5.45826733e-01,  2.23604727e+00],\n",
              "         [-1.82733119e+00,  5.73998034e-01, -7.97509849e-01, ...,\n",
              "          -1.01747942e+00, -7.55283311e-02,  2.08927631e+00],\n",
              "         [-1.77726507e+00,  1.13865566e+00, -1.08018911e+00, ...,\n",
              "          -7.94608593e-01, -8.21889162e-01,  2.28720975e+00],\n",
              "         ...,\n",
              "         [-1.27909148e+00,  1.34583747e+00,  1.05723299e-01, ...,\n",
              "          -2.04388952e+00, -4.08963174e-01,  1.05442297e+00],\n",
              "         [-1.28060663e+00,  1.53821802e+00, -1.14264697e-01, ...,\n",
              "          -7.35574782e-01, -2.82427698e-01,  1.99164832e+00],\n",
              "         [-7.75298655e-01,  1.62875211e+00,  8.68363082e-01, ...,\n",
              "           5.72067499e-01, -7.97819793e-01,  1.57797086e+00]],\n",
              " \n",
              "        [[-1.23458111e+00, -2.56487519e-01, -7.76895106e-01, ...,\n",
              "          -7.12774619e-02,  9.20793295e-01,  2.58316422e+00],\n",
              "         [-9.63011205e-01,  5.86698294e-01, -1.58736646e+00, ...,\n",
              "          -6.40762985e-01,  1.75431520e-01,  2.42147613e+00],\n",
              "         [-1.48151636e+00,  1.49060917e+00, -1.18249822e+00, ...,\n",
              "          -2.43649647e-01, -3.65618944e-01,  3.06922483e+00],\n",
              "         ...,\n",
              "         [-1.41526663e+00,  1.21058762e+00, -1.57564506e-01, ...,\n",
              "          -9.97601211e-01, -1.06751107e-01,  1.71446788e+00],\n",
              "         [-1.74733627e+00,  9.36622798e-01, -3.36572558e-01, ...,\n",
              "          -3.09059918e-01,  2.87500679e-01,  2.21194816e+00],\n",
              "         [-1.01137245e+00,  1.06097126e+00,  2.86677241e-01, ...,\n",
              "           6.80599511e-01, -7.97752500e-01,  2.27092791e+00]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[-8.89385283e-01,  6.07050419e-01,  4.38338548e-01, ...,\n",
              "          -5.78748286e-01,  7.17602611e-01,  2.51826215e+00],\n",
              "         [-9.59960938e-01,  1.42426991e+00,  1.90393801e-03, ...,\n",
              "          -7.79315531e-01, -5.59919655e-01,  3.11355543e+00],\n",
              "         [-2.10461807e+00,  1.54191065e+00, -4.87776369e-01, ...,\n",
              "          -1.02188134e+00,  3.55913222e-01,  4.44237709e+00],\n",
              "         ...,\n",
              "         [-1.68369985e+00,  3.56960505e-01, -2.64299124e-01, ...,\n",
              "          -1.30283713e+00, -1.97421834e-01,  2.87952852e+00],\n",
              "         [-2.34050322e+00,  8.92399848e-02,  2.00805783e-01, ...,\n",
              "          -7.91633546e-01,  2.86227375e-01,  2.37668419e+00],\n",
              "         [-6.25589371e-01,  8.13497126e-01, -2.85402145e-02, ...,\n",
              "           5.09303331e-01, -6.36921585e-01,  2.18702292e+00]],\n",
              " \n",
              "        [[-3.20409387e-02,  7.63726890e-01,  6.97975159e-01, ...,\n",
              "          -4.17000979e-01,  1.24935620e-01,  1.74975026e+00],\n",
              "         [-5.01641154e-01,  8.28719318e-01,  6.75139904e-01, ...,\n",
              "          -4.53110307e-01, -6.20691299e-01,  2.48756742e+00],\n",
              "         [-8.72121632e-01,  1.25866473e+00,  7.75909007e-01, ...,\n",
              "          -2.79999226e-01, -3.31541032e-01,  4.12155056e+00],\n",
              "         ...,\n",
              "         [-1.41692531e+00,  5.58448553e-01,  8.49574506e-02, ...,\n",
              "          -3.23066503e-01, -6.33431554e-01,  3.30849195e+00],\n",
              "         [-1.67347181e+00,  1.27993301e-01,  5.40282607e-01, ...,\n",
              "          -4.81396556e-01, -2.54249513e-01,  2.61713052e+00],\n",
              "         [-2.97803640e-01,  1.32690862e-01,  4.13550019e-01, ...,\n",
              "           3.75997543e-01, -1.11842287e+00,  2.37522316e+00]],\n",
              " \n",
              "        [[-5.35707593e-01,  6.22064658e-02,  1.10556535e-01, ...,\n",
              "          -4.35264230e-01,  5.90926945e-01,  1.45422876e+00],\n",
              "         [-9.01839793e-01,  1.54521480e-01,  2.49230936e-01, ...,\n",
              "           2.58631520e-02, -1.74032971e-01,  2.55247736e+00],\n",
              "         [-8.71436298e-01,  1.18438326e-01, -2.66053885e-01, ...,\n",
              "          -2.23711021e-02, -2.52597928e-01,  2.80348301e+00],\n",
              "         ...,\n",
              "         [-1.11458397e+00, -4.86614913e-01, -7.56084502e-01, ...,\n",
              "           9.35343653e-02, -1.30435809e-01,  1.51696646e+00],\n",
              "         [-6.57901585e-01, -7.19465256e-01, -4.98008430e-01, ...,\n",
              "          -5.29173613e-01, -1.55974910e-01,  9.17974591e-01],\n",
              "         [-1.60820305e-01, -5.15782356e-01, -2.16107383e-01, ...,\n",
              "           8.46831352e-02, -8.78714859e-01,  7.08851516e-01]]],\n",
              "       dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cProfile\n",
        "config = Config()\n",
        "game = Game()\n",
        "nn = Network()\n",
        "\n",
        "with cProfile.Profile() as pr:\n",
        "  #run_mcts(config, game, nn)\n",
        "  image = Game().make_image(-1)\n",
        "  nn.inference(image)\n",
        "  nn.inference(image)\n",
        "  nn.inference(image)\n",
        "  nn.inference(image)\n",
        "  nn.inference(image)\n",
        "  nn.inference(image)\n",
        "  nn.inference(image)\n",
        "  nn.inference(image)\n",
        "  nn.inference(image)\n",
        "  nn.inference(image)"
      ],
      "metadata": {
        "id": "9k9EhrNT7sEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pr.dump_stats('restats')"
      ],
      "metadata": {
        "id": "KUrCZYHxuDBP"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pstats\n",
        "from pstats import SortKey\n",
        "p = pstats.Stats('restats')\n",
        "#p.sort_stats('tottime')\n",
        "#p.print_callees()\n",
        "#p.print_stats()\n",
        "p.sort_stats(1)\n",
        "p.print_stats()"
      ],
      "metadata": {
        "id": "PKeaNE8F-mDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cProfile\n",
        "config = Config()\n",
        "network = Network(True)\n",
        "\n",
        "with cProfile.Profile() as pr:\n",
        "  run_mcts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "l6SwjaCxGGx7",
        "outputId": "c497a908-01d4-42b1-883f-85bb2d59852a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r n b q k b n r\n",
            "p p p p p p p p\n",
            ". . . . . . . .\n",
            ". . . . . . . .\n",
            ". . . . . . . .\n",
            ". . . . . . . .\n",
            "P P P P P P P P\n",
            "R N B Q K B N R\n",
            "r n b q k b n r\n",
            "p p p p p p p p\n",
            ". . . . . . . .\n",
            ". . . . . . . .\n",
            ". . . . . . . .\n",
            "P . . . . . . .\n",
            ". P P P P P P P\n",
            "R N B Q K B N R\n",
            "r . b q k b n r\n",
            "p p p p p p p p\n",
            ". . n . . . . .\n",
            ". . . . . . . .\n",
            ". . . . . . . .\n",
            "P . . . . . . .\n",
            ". P P P P P P P\n",
            "R N B Q K B N R\n",
            "r . b q k b n r\n",
            "p p p p p p p p\n",
            ". . n . . . . .\n",
            ". . . . . . . .\n",
            ". . . . . . . .\n",
            "P . N . . . . .\n",
            ". P P P P P P P\n",
            "R . B Q K B N R\n",
            "r . b q k b n r\n",
            "p p p p p p p p\n",
            ". . . . . . . .\n",
            ". . . . n . . .\n",
            ". . . . . . . .\n",
            "P . N . . . . .\n",
            ". P P P P P P P\n",
            "R . B Q K B N R\n",
            "r . b q k b n r\n",
            "p p p p p p p p\n",
            ". . . . . . . .\n",
            ". . . . n . . .\n",
            ". . . . . . . .\n",
            "P P N . . . . .\n",
            ". . P P P P P P\n",
            "R . B Q K B N R\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-36c2dc75a696>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_moves\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_mcts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore_search_statistics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-de92e2eb65b4>\u001b[0m in \u001b[0;36mrun_mcts\u001b[0;34m(config, game, network)\u001b[0m\n\u001b[1;32m     45\u001b[0m       \u001b[0msearch_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscratch_game\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mbackpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscratch_game\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_play\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-de92e2eb65b4>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(node, game, network)\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_play\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_play\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m   \u001b[0mpolicy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy_logits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegal_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m   \u001b[0mpolicy_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-8f4a89610d56>\u001b[0m in \u001b[0;36mlegal_actions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mlegal_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Game specific calculation of legal actions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_legal_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-4150164057d2>\u001b[0m in \u001b[0;36mgenerate_legal_actions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    151\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_legal_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0mmoves\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_legal_moves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m     \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmove\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmoves\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-4150164057d2>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    151\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_legal_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0mmoves\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_legal_moves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m     \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmove\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmoves\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/chess/__init__.py\u001b[0m in \u001b[0;36mgenerate_legal_moves\u001b[0;34m(self, from_mask, to_mask)\u001b[0m\n\u001b[1;32m   3595\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3596\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mmove\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_pseudo_legal_moves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3597\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_safe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblockers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3598\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/chess/__init__.py\u001b[0m in \u001b[0;36m_is_safe\u001b[0;34m(self, king, blockers, move)\u001b[0m\n\u001b[1;32m   3552\u001b[0m                         not self._ep_skewered(king, move.from_square))\n\u001b[1;32m   3553\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3554\u001b[0;31m             return bool(not blockers & BB_SQUARES[move.from_square] or\n\u001b[0m\u001b[1;32m   3555\u001b[0m                         ray(move.from_square, move.to_square) & BB_SQUARES[king])\n\u001b[1;32m   3556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# config = Config()\n",
        "# network_1 = zero(config)"
      ],
      "metadata": {
        "id": "tsgLx3x98qnB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}